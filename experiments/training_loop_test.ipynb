{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T21:46:36.595031711Z",
     "start_time": "2023-11-14T21:46:36.484313596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "import sys\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False)\n",
    "\n",
    "# Class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T21:46:36.729986935Z",
     "start_time": "2023-11-14T21:46:36.589703578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dress  Bag  Coat  Coat\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "print('  '.join(classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "The model we’ll use in this example is a variant of LeNet-5 - it should\n",
    "be familiar if you’ve watched the previous videos in this series.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T21:46:36.737941654Z",
     "start_time": "2023-11-14T21:46:36.701712250Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyTorch models inherit from torch.nn.Module\n",
    "class GarmentClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GarmentClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "model = GarmentClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "\n",
    "For this example, we’ll be using a cross-entropy loss. For demonstration\n",
    "purposes, we’ll create batches of dummy output and label values, run\n",
    "them through the loss function, and examine the result.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T21:46:36.738349747Z",
     "start_time": "2023-11-14T21:46:36.701816961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5198, 0.7910, 0.7084, 0.4269, 0.2749, 0.3064, 0.9589, 0.9470, 0.2710,\n",
      "         0.2559],\n",
      "        [0.2141, 0.2863, 0.6860, 0.6212, 0.3132, 0.0480, 0.1436, 0.6864, 0.5413,\n",
      "         0.6771],\n",
      "        [0.2362, 0.0017, 0.3304, 0.2004, 0.3659, 0.0420, 0.2389, 0.2084, 0.9578,\n",
      "         0.1744],\n",
      "        [0.7195, 0.5329, 0.3082, 0.0897, 0.5054, 0.3988, 0.5106, 0.9650, 0.6981,\n",
      "         0.3625]])\n",
      "tensor([1, 5, 3, 7])\n",
      "Total loss for this batch: 2.2715394496917725\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# NB: Loss functions expect data in batches, so we're creating batches of 4\n",
    "# Represents the model's confidence in each of the 10 classes for a given input\n",
    "dummy_outputs = torch.rand(4, 10)\n",
    "# Represents the correct class among the 10 being tested\n",
    "dummy_labels = torch.tensor([1, 5, 3, 7])\n",
    "    \n",
    "print(dummy_outputs)\n",
    "print(dummy_labels)\n",
    "\n",
    "loss = loss_fn(dummy_outputs, dummy_labels)\n",
    "print('Total loss for this batch: {}'.format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T21:46:36.738438497Z",
     "start_time": "2023-11-14T21:46:36.722239977Z"
    }
   },
   "outputs": [],
   "source": [
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T21:46:36.776324782Z",
     "start_time": "2023-11-14T21:46:36.728963949Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    for i, data in enumerate(training_loader):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "    \n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print(f'Loss after sample {i + 1}: {last_loss}')\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "    \n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T21:50:41.606375202Z",
     "start_time": "2023-11-14T21:46:36.769786221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "Loss after sample 1000: 1.8948269291818143\n",
      "Loss after sample 2000: 0.8438374758260324\n",
      "Loss after sample 3000: 0.6965665432717651\n",
      "Loss after sample 4000: 0.6397723929099739\n",
      "Loss after sample 5000: 0.5723190686730668\n",
      "Loss after sample 6000: 0.5367084819879383\n",
      "Loss after sample 7000: 0.53121544493502\n",
      "Loss after sample 8000: 0.48371551104914395\n",
      "Loss after sample 9000: 0.4977609337142203\n",
      "Loss after sample 10000: 0.45415499647147956\n",
      "Loss after sample 11000: 0.4681046385422378\n",
      "Loss after sample 12000: 0.4350579361511627\n",
      "Loss after sample 13000: 0.4101076378423022\n",
      "Loss after sample 14000: 0.4074860269461642\n",
      "Loss after sample 15000: 0.3666826373486547\n",
      "#############################################################\n",
      "Epoch results:\n",
      "Loss train 0.3666826373486547 valid loss: 0.4225538671016693\n",
      "F1 score train None valid f1 score 0.8436696056404278\n",
      "#############################################################\n",
      "\n",
      "\n",
      "EPOCH 2:\n",
      "Loss after sample 1000: 0.3964561949640047\n",
      "Loss after sample 2000: 0.40060249132546594\n",
      "Loss after sample 3000: 0.37331868682239294\n",
      "Loss after sample 4000: 0.3698380863775383\n",
      "Loss after sample 5000: 0.359322283890564\n",
      "Loss after sample 6000: 0.344119315091928\n",
      "Loss after sample 7000: 0.392370111680124\n",
      "Loss after sample 8000: 0.3542991964507091\n",
      "Loss after sample 9000: 0.3574430078854202\n",
      "Loss after sample 10000: 0.363366196230636\n",
      "Loss after sample 11000: 0.36756309505524404\n",
      "Loss after sample 12000: 0.36090118707047075\n",
      "Loss after sample 13000: 0.34031851515086603\n",
      "Loss after sample 14000: 0.33587522497224565\n",
      "Loss after sample 15000: 0.33718310329999074\n",
      "#############################################################\n",
      "Epoch results:\n",
      "Loss train 0.33718310329999074 valid loss: 0.3434949517250061\n",
      "F1 score train None valid f1 score 0.8711222276104793\n",
      "#############################################################\n",
      "\n",
      "\n",
      "EPOCH 3:\n",
      "Loss after sample 1000: 0.33605103578147827\n",
      "Loss after sample 2000: 0.33029256611780144\n",
      "Loss after sample 3000: 0.31227563998670665\n",
      "Loss after sample 4000: 0.33643888223615065\n",
      "Loss after sample 5000: 0.31545035575809016\n",
      "Loss after sample 6000: 0.3353706608252396\n",
      "Loss after sample 7000: 0.3181287261054531\n",
      "Loss after sample 8000: 0.3197279141941981\n",
      "Loss after sample 9000: 0.3100363266064087\n",
      "Loss after sample 10000: 0.31323639499933054\n",
      "Loss after sample 11000: 0.309601072932237\n",
      "Loss after sample 12000: 0.33004182971634144\n",
      "Loss after sample 13000: 0.3087362564976938\n",
      "Loss after sample 14000: 0.29992392681183266\n",
      "Loss after sample 15000: 0.3009665307175601\n",
      "#############################################################\n",
      "Epoch results:\n",
      "Loss train 0.3009665307175601 valid loss: 0.3225918114185333\n",
      "F1 score train None valid f1 score 0.8822948049155878\n",
      "#############################################################\n",
      "\n",
      "\n",
      "EPOCH 4:\n",
      "Loss after sample 1000: 0.2959381441841979\n",
      "Loss after sample 2000: 0.2952034954004339\n",
      "Loss after sample 3000: 0.28695425906779565\n",
      "Loss after sample 4000: 0.2786060342247365\n",
      "Loss after sample 5000: 0.2740020732009143\n",
      "Loss after sample 6000: 0.3025929149073563\n",
      "Loss after sample 7000: 0.3029305645609311\n",
      "Loss after sample 8000: 0.29692714062135744\n",
      "Loss after sample 9000: 0.2740064848544571\n",
      "Loss after sample 10000: 0.30283042010660577\n",
      "Loss after sample 11000: 0.2864590364655014\n",
      "Loss after sample 12000: 0.27914940144854333\n",
      "Loss after sample 13000: 0.2822278544697656\n",
      "Loss after sample 14000: 0.3110994354679933\n",
      "Loss after sample 15000: 0.30094519587814467\n",
      "#############################################################\n",
      "Epoch results:\n",
      "Loss train 0.30094519587814467 valid loss: 0.333598792552948\n",
      "F1 score train None valid f1 score 0.8760136407938293\n",
      "#############################################################\n",
      "\n",
      "\n",
      "EPOCH 5:\n",
      "Loss after sample 1000: 0.25130565677442335\n",
      "Loss after sample 2000: 0.27169893330563355\n",
      "Loss after sample 3000: 0.2692950501247596\n",
      "Loss after sample 4000: 0.293532781601989\n",
      "Loss after sample 5000: 0.27672379299606836\n",
      "Loss after sample 6000: 0.2571050627835357\n",
      "Loss after sample 7000: 0.2766805603730318\n",
      "Loss after sample 8000: 0.27343616657220265\n",
      "Loss after sample 9000: 0.27387927249669153\n",
      "Loss after sample 10000: 0.2829835030738868\n",
      "Loss after sample 11000: 0.28410078788620013\n",
      "Loss after sample 12000: 0.27191000546769645\n",
      "Loss after sample 13000: 0.2735727273097109\n",
      "Loss after sample 14000: 0.2712390693870257\n",
      "Loss after sample 15000: 0.2741728221793237\n",
      "#############################################################\n",
      "Epoch results:\n",
      "Loss train 0.2741728221793237 valid loss: 0.30982863903045654\n",
      "F1 score train None valid f1 score 0.8857574887149984\n",
      "#############################################################\n",
      "\n",
      "\n",
      "EPOCH 6:\n",
      "Loss after sample 1000: 0.2578551418530733\n",
      "Loss after sample 2000: 0.26420953720135004\n",
      "Loss after sample 3000: 0.2415430691381116\n",
      "Loss after sample 4000: 0.2623550012869073\n",
      "Loss after sample 5000: 0.24587637192223155\n",
      "Loss after sample 6000: 0.25479129739616835\n",
      "Loss after sample 7000: 0.25876430913573495\n",
      "Loss after sample 8000: 0.2571227632504815\n",
      "Loss after sample 9000: 0.2597401226194278\n",
      "Loss after sample 10000: 0.25930700469876866\n",
      "Loss after sample 11000: 0.26095125547022324\n",
      "Loss after sample 12000: 0.2599779267328886\n",
      "Loss after sample 13000: 0.2829638749834867\n",
      "Loss after sample 14000: 0.2683806853009737\n",
      "Loss after sample 15000: 0.2587134824857203\n",
      "#############################################################\n",
      "Epoch results:\n",
      "Loss train 0.2587134824857203 valid loss: 0.29062747955322266\n",
      "F1 score train None valid f1 score 0.8952366563352573\n",
      "#############################################################\n",
      "\n",
      "\n",
      "EPOCH 7:\n",
      "Loss after sample 1000: 0.23393809885407973\n",
      "Loss after sample 2000: 0.2504173402649194\n",
      "Loss after sample 3000: 0.2517231022728791\n",
      "Loss after sample 4000: 0.24583361216021035\n",
      "Loss after sample 5000: 0.23446456919747333\n",
      "Loss after sample 6000: 0.23500064767194886\n",
      "Loss after sample 7000: 0.2545689602797275\n",
      "Loss after sample 8000: 0.2468390069967263\n",
      "Loss after sample 9000: 0.264007577584116\n",
      "Loss after sample 10000: 0.24354718797334682\n",
      "Loss after sample 11000: 0.23644085970889137\n",
      "Loss after sample 12000: 0.2554398642259221\n",
      "Loss after sample 13000: 0.2400604947648517\n",
      "Loss after sample 14000: 0.24823297965965072\n",
      "Loss after sample 15000: 0.24647852648416482\n",
      "#############################################################\n",
      "Epoch results:\n",
      "Loss train 0.24647852648416482 valid loss: 0.3253791332244873\n",
      "F1 score train None valid f1 score 0.8840010786335416\n",
      "#############################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from training.validation_metrics import calculate_metric\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter(f'logs/fashion_trainer_{timestamp}')\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 7\n",
    "\n",
    "best_vloss = sys.float_info.max\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "    \n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "    \n",
    "    # Set the model to evaluation mode, disabling dropout and using population \n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "    running_vloss = 0.0\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "    \n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print(\"#############################################################\")\n",
    "    print(\"Epoch results:\")\n",
    "    print(f'Loss train {avg_loss} valid loss: {avg_vloss}')\n",
    "    validation_f1_score = calculate_metric(model, validation_loader, metric=f1_score)\n",
    "    train_f1_score = None\n",
    "    print(f'F1 score train {train_f1_score} valid f1 score {validation_f1_score}')\n",
    "    print(\"#############################################################\\n\\n\")\n",
    "    \n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    \n",
    "    \n",
    "    writer.add_scalars('Macro_averaged_f1_score',\n",
    "                    { 'Validation' : validation_f1_score},\n",
    "                    epoch_number + 1)\n",
    "    \n",
    "    writer.flush()\n",
    "    \n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = f'model_{timestamp}_{epoch_number}'\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T21:50:41.612641161Z",
     "start_time": "2023-11-14T21:50:41.608215883Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T21:50:41.624735886Z",
     "start_time": "2023-11-14T21:50:41.611964197Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.cuda.current_device()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T21:50:41.643982765Z",
     "start_time": "2023-11-14T21:50:41.623791200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch.cuda.device at 0x7f282989f8d0>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device(0)\n",
    "#tensorboard --logdir=logs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T21:50:41.686872220Z",
     "start_time": "2023-11-14T21:50:41.673658888Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
