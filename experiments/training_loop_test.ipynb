{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T14:29:52.671407691Z",
     "start_time": "2023-11-14T14:29:52.635259004Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T14:29:52.771673284Z",
     "start_time": "2023-11-14T14:29:52.644137175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False)\n",
    "\n",
    "# Class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T14:29:52.905994228Z",
     "start_time": "2023-11-14T14:29:52.755556649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shirt  Pullover  Bag  Ankle Boot\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "print('  '.join(classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "The model we’ll use in this example is a variant of LeNet-5 - it should\n",
    "be familiar if you’ve watched the previous videos in this series.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T14:29:52.912737357Z",
     "start_time": "2023-11-14T14:29:52.887578076Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# PyTorch models inherit from torch.nn.Module\n",
    "class GarmentClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GarmentClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "model = GarmentClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Function\n",
    "\n",
    "For this example, we’ll be using a cross-entropy loss. For demonstration\n",
    "purposes, we’ll create batches of dummy output and label values, run\n",
    "them through the loss function, and examine the result.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T14:29:52.913052763Z",
     "start_time": "2023-11-14T14:29:52.887731429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3440, 0.8935, 0.7452, 0.6550, 0.5936, 0.3402, 0.6458, 0.4663, 0.4907,\n",
      "         0.2924],\n",
      "        [0.3396, 0.8240, 0.5065, 0.7969, 0.0369, 0.4926, 0.9307, 0.0121, 0.0261,\n",
      "         0.8869],\n",
      "        [0.7594, 0.6954, 0.4748, 0.7437, 0.5973, 0.0275, 0.3776, 0.6620, 0.1607,\n",
      "         0.9689],\n",
      "        [0.3853, 0.1868, 0.6020, 0.8251, 0.3202, 0.9909, 0.5019, 0.3162, 0.8564,\n",
      "         0.5942]])\n",
      "tensor([1, 5, 3, 7])\n",
      "Total loss for this batch: 2.261411428451538\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# NB: Loss functions expect data in batches, so we're creating batches of 4\n",
    "# Represents the model's confidence in each of the 10 classes for a given input\n",
    "dummy_outputs = torch.rand(4, 10)\n",
    "# Represents the correct class among the 10 being tested\n",
    "dummy_labels = torch.tensor([1, 5, 3, 7])\n",
    "    \n",
    "print(dummy_outputs)\n",
    "print(dummy_labels)\n",
    "\n",
    "loss = loss_fn(dummy_outputs, dummy_labels)\n",
    "print('Total loss for this batch: {}'.format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T14:29:52.952851420Z",
     "start_time": "2023-11-14T14:29:52.894739922Z"
    }
   },
   "outputs": [],
   "source": [
    "# Optimizers specified in the torch.optim package\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "0.1"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy_score(model, val_loader):       \n",
    "    model.eval()\n",
    "    with torch.no_grad(): \n",
    "        correct, total = 0, 0\n",
    "        for images, labels in val_loader:            \n",
    "            test_output = model(images)\n",
    "            pred_y = torch.max(test_output, dim = 1)[1].data.squeeze()\n",
    "            correct += (pred_y == labels).sum().item() \n",
    "            total += pred_y.size(dim = 0)\n",
    "    \n",
    "    return correct/total\n",
    "accuracy_score(model, validation_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T14:29:57.642204942Z",
     "start_time": "2023-11-14T14:29:52.939719707Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[66], line 18\u001B[0m\n\u001B[1;32m     14\u001B[0m             true_labels \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat((true_labels, labels))\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f1_score([\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m3\u001B[39m,\u001B[38;5;241m2\u001B[39m], [\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m3\u001B[39m,\u001B[38;5;241m3\u001B[39m])\n\u001B[0;32m---> 18\u001B[0m \u001B[43mmacro_averaged_accuracy_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_loader\u001B[49m\u001B[43m)\u001B[49m \n",
      "Cell \u001B[0;32mIn[66], line 16\u001B[0m, in \u001B[0;36mmacro_averaged_accuracy_score\u001B[0;34m(model, val_loader)\u001B[0m\n\u001B[1;32m     13\u001B[0m         predicted_labels \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat((predicted_labels, predictions))\n\u001B[1;32m     14\u001B[0m         true_labels \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat((true_labels, labels))\n\u001B[0;32m---> 16\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf1_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/Bird-classification-model/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:214\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    208\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m    210\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m    211\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m    212\u001B[0m         )\n\u001B[1;32m    213\u001B[0m     ):\n\u001B[0;32m--> 214\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[1;32m    219\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[1;32m    220\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[1;32m    221\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    222\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    223\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[1;32m    224\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/Bird-classification-model/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1239\u001B[0m, in \u001B[0;36mf1_score\u001B[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001B[0m\n\u001B[1;32m   1070\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[1;32m   1071\u001B[0m     {\n\u001B[1;32m   1072\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray-like\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse matrix\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1097\u001B[0m     zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarn\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1098\u001B[0m ):\n\u001B[1;32m   1099\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001B[39;00m\n\u001B[1;32m   1100\u001B[0m \n\u001B[1;32m   1101\u001B[0m \u001B[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1237\u001B[0m \u001B[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001B[39;00m\n\u001B[1;32m   1238\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1239\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfbeta_score\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1240\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1241\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1242\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1243\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1244\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpos_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1245\u001B[0m \u001B[43m        \u001B[49m\u001B[43maverage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1246\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1247\u001B[0m \u001B[43m        \u001B[49m\u001B[43mzero_division\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mzero_division\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1248\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/Bird-classification-model/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:187\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    185\u001B[0m global_skip_validation \u001B[38;5;241m=\u001B[39m get_config()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskip_parameter_validation\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m global_skip_validation:\n\u001B[0;32m--> 187\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    189\u001B[0m func_sig \u001B[38;5;241m=\u001B[39m signature(func)\n\u001B[1;32m    191\u001B[0m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/Bird-classification-model/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1413\u001B[0m, in \u001B[0;36mfbeta_score\u001B[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001B[0m\n\u001B[1;32m   1251\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[1;32m   1252\u001B[0m     {\n\u001B[1;32m   1253\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray-like\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse matrix\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1280\u001B[0m     zero_division\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwarn\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1281\u001B[0m ):\n\u001B[1;32m   1282\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute the F-beta score.\u001B[39;00m\n\u001B[1;32m   1283\u001B[0m \n\u001B[1;32m   1284\u001B[0m \u001B[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1410\u001B[0m \u001B[38;5;124;03m    0.38...\u001B[39;00m\n\u001B[1;32m   1411\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1413\u001B[0m     _, _, f, _ \u001B[38;5;241m=\u001B[39m \u001B[43mprecision_recall_fscore_support\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1414\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1415\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1416\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1417\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1418\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpos_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1419\u001B[0m \u001B[43m        \u001B[49m\u001B[43maverage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1420\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwarn_for\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mf-score\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1421\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1422\u001B[0m \u001B[43m        \u001B[49m\u001B[43mzero_division\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mzero_division\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1423\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1424\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f\n",
      "File \u001B[0;32m~/PycharmProjects/Bird-classification-model/venv/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:187\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    185\u001B[0m global_skip_validation \u001B[38;5;241m=\u001B[39m get_config()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskip_parameter_validation\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    186\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m global_skip_validation:\n\u001B[0;32m--> 187\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    189\u001B[0m func_sig \u001B[38;5;241m=\u001B[39m signature(func)\n\u001B[1;32m    191\u001B[0m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/Bird-classification-model/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1724\u001B[0m, in \u001B[0;36mprecision_recall_fscore_support\u001B[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001B[0m\n\u001B[1;32m   1566\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001B[39;00m\n\u001B[1;32m   1567\u001B[0m \n\u001B[1;32m   1568\u001B[0m \u001B[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1721\u001B[0m \u001B[38;5;124;03m array([2, 2, 2]))\u001B[39;00m\n\u001B[1;32m   1722\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1723\u001B[0m zero_division_value \u001B[38;5;241m=\u001B[39m _check_zero_division(zero_division)\n\u001B[0;32m-> 1724\u001B[0m labels \u001B[38;5;241m=\u001B[39m \u001B[43m_check_set_wise_labels\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpos_label\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1726\u001B[0m \u001B[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001B[39;00m\n\u001B[1;32m   1727\u001B[0m samplewise \u001B[38;5;241m=\u001B[39m average \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msamples\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/PycharmProjects/Bird-classification-model/venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1518\u001B[0m, in \u001B[0;36m_check_set_wise_labels\u001B[0;34m(y_true, y_pred, average, labels, pos_label)\u001B[0m\n\u001B[1;32m   1516\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   1517\u001B[0m             average_options\u001B[38;5;241m.\u001B[39mremove(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msamples\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1518\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1519\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTarget is \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m but average=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. Please \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1520\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchoose another average setting, one of \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (y_type, average_options)\n\u001B[1;32m   1521\u001B[0m         )\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m pos_label \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m   1523\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m   1524\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNote that pos_label (set to \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m) is ignored when \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124maverage != \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m (got \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m). You may use \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1528\u001B[0m         \u001B[38;5;167;01mUserWarning\u001B[39;00m,\n\u001B[1;32m   1529\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score, f1_score\n",
    "\n",
    "def macro_averaged_accuracy_score(model, val_loader):\n",
    "    model.eval()\n",
    "    true_labels = torch.Tensor()\n",
    "    predicted_labels = torch.Tensor()\n",
    "    \n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for images, labels in val_loader:\n",
    "            validation_output = model(images)\n",
    "            predictions = torch.max(validation_output, dim = 1)[1].data.squeeze()\n",
    "            predicted_labels = torch.cat((predicted_labels, predictions))\n",
    "            true_labels = torch.cat((true_labels, labels))\n",
    "            \n",
    "    return f1_score([1,2,3,2], [1,2,3,3])\n",
    "        \n",
    "macro_averaged_accuracy_score(model, validation_loader) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T15:44:00.391060656Z",
     "start_time": "2023-11-14T15:43:57.114660744Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T14:29:57.647350890Z",
     "start_time": "2023-11-14T14:29:57.641004535Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    for i, data in enumerate(training_loader):\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "    \n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print(f'Loss after sample {i + 1}: {last_loss}')\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "    \n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T14:32:25.567364016Z",
     "start_time": "2023-11-14T14:29:57.652942324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "Sample (1000,) loss: 1.8058394292965532\n",
      "Sample (2000,) loss: 0.9147078606933355\n",
      "Sample (3000,) loss: 0.7403633297905325\n",
      "Sample (4000,) loss: 0.6858506467612461\n",
      "Sample (5000,) loss: 0.6130340623483062\n",
      "Sample (6000,) loss: 0.5634890499399043\n",
      "Sample (7000,) loss: 0.5426104303358589\n",
      "Sample (8000,) loss: 0.5254134572941112\n",
      "Sample (9000,) loss: 0.4902106414614245\n",
      "Sample (10000,) loss: 0.4972792391187977\n",
      "Sample (11000,) loss: 0.4766199467619881\n",
      "Sample (12000,) loss: 0.4651701233551139\n",
      "Sample (13000,) loss: 0.4476124069169164\n",
      "Sample (14000,) loss: 0.43737198541482214\n",
      "Sample (15000,) loss: 0.4219488693092135\n",
      "#############################################################\n",
      "Epoch results\n",
      "Loss train 0.4219488693092135 valid loss: 0.42712998390197754\n",
      "Accuracy train None valid accuracy 0.8449\n",
      "#############################################################\n",
      "EPOCH 2:\n",
      "Sample (1000,) loss: 0.40847717969981023\n",
      "Sample (2000,) loss: 0.40496539729990766\n",
      "Sample (3000,) loss: 0.4089880636719754\n",
      "Sample (4000,) loss: 0.38273672771913697\n",
      "Sample (5000,) loss: 0.3705935417918954\n",
      "Sample (6000,) loss: 0.3928431412904174\n",
      "Sample (7000,) loss: 0.3731054632879095\n",
      "Sample (8000,) loss: 0.3553963971210178\n",
      "Sample (9000,) loss: 0.3797744515037921\n",
      "Sample (10000,) loss: 0.3676812361313205\n",
      "Sample (11000,) loss: 0.34108356964669656\n",
      "Sample (12000,) loss: 0.33977544549309824\n",
      "Sample (13000,) loss: 0.3401748430733278\n",
      "Sample (14000,) loss: 0.3514560637955437\n",
      "Sample (15000,) loss: 0.3658437417635578\n",
      "#############################################################\n",
      "Epoch results\n",
      "Loss train 0.3658437417635578 valid loss: 0.37478402256965637\n",
      "Accuracy train None valid accuracy 0.8633\n",
      "#############################################################\n",
      "EPOCH 3:\n",
      "Sample (1000,) loss: 0.3332055129884393\n",
      "Sample (2000,) loss: 0.3377949217185087\n",
      "Sample (3000,) loss: 0.3148240973624743\n",
      "Sample (4000,) loss: 0.31533073775688536\n",
      "Sample (5000,) loss: 0.3237601719531813\n",
      "Sample (6000,) loss: 0.3237856711543136\n",
      "Sample (7000,) loss: 0.34438366549003696\n",
      "Sample (8000,) loss: 0.30353377078319865\n",
      "Sample (9000,) loss: 0.30845503989971623\n",
      "Sample (10000,) loss: 0.32171909782382135\n",
      "Sample (11000,) loss: 0.31344720139721904\n",
      "Sample (12000,) loss: 0.3314453453866736\n",
      "Sample (13000,) loss: 0.2981739034151251\n",
      "Sample (14000,) loss: 0.3273817141148029\n",
      "Sample (15000,) loss: 0.33595059893233703\n",
      "#############################################################\n",
      "Epoch results\n",
      "Loss train 0.33595059893233703 valid loss: 0.3404513895511627\n",
      "Accuracy train None valid accuracy 0.8723\n",
      "#############################################################\n"
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "    \n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "    \n",
    "    # Set the model to evaluation mode, disabling dropout and using population \n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "    running_vloss = 0.0\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "    \n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print(\"#############################################################\")\n",
    "    print(\"Epoch results\")\n",
    "    print(f'Loss train {avg_loss} valid loss: {avg_vloss}')\n",
    "    validation_accuracy = accuracy_score(model, validation_loader)\n",
    "    train_accuracy = None\n",
    "    print(f'Accuracy train {train_accuracy} valid accuracy {validation_accuracy}')\n",
    "    print(\"#############################################################\\n\\n\")\n",
    "    \n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    \n",
    "    \n",
    "    writer.add_scalars('Accuracy',\n",
    "                    { 'Validation accuracy' : validation_accuracy},\n",
    "                    epoch_number + 1)\n",
    "    \n",
    "    writer.flush()\n",
    "    \n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8333333333333333"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "y_true = [1,2,1,2,2]\n",
    "y_pred = [1,2,1,2,1]\n",
    "precision_score(y_true, y_pred, average='macro')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-14T16:32:42.057180438Z",
     "start_time": "2023-11-14T16:32:42.043197570Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
