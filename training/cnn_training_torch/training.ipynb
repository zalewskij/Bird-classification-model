{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68726db873b8dce7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Classes and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e1e43838f725aab",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T19:05:27.380089788Z",
     "start_time": "2023-11-28T19:05:27.363351417Z"
    }
   },
   "outputs": [],
   "source": [
    "from birdclassification.preprocessing.filtering import filter_recordings_30\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from training.dataset import Recordings30\n",
    "from birdclassification.visualization.plots import plot_torch_spectrogram\n",
    "from training.cnn_training_torch.CNN_model import CNNNetwork\n",
    "from torchsummary import summary\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "816e75a17dc17a2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T14:33:31.732236976Z",
     "start_time": "2023-11-28T14:33:31.727991089Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacek/PycharmProjects/Bird-classification-model/venv/lib/python3.11/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "SEED = 123\n",
    "RECORDINGS_DIR = '/mnt/d/recordings_30/'\n",
    "NOISES_DIR = '/aaa/'\n",
    "\n",
    "SAMPLE_RATE = 32000\n",
    "NUM_SAMPLES = SAMPLE_RATE * 1\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2500b5a9a57f175",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Prepare dataset and dataloaders, visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63a6e7eb0ea22a95",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T14:34:08.210415070Z",
     "start_time": "2023-11-28T14:34:02.090948909Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacek/PycharmProjects/Bird-classification-model/birdclassification/preprocessing/filtering.py:72: DtypeWarning: Columns (10,39,43,44,45,46,47,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  recordings = pd.read_csv(filepath_recordings)\n"
     ]
    }
   ],
   "source": [
    "df = filter_recordings_30(\"../../data/xeno_canto_recordings.csv\", \"../../data/bird-list-extended.csv\", )\n",
    "\n",
    "#subset for test purpose\n",
    "# df = df.sample(frac = 0.1, random_state=SEED)\n",
    "\n",
    "train_df, test_val_df = train_test_split(df, stratify=df['Latin name'], test_size=0.2, random_state = SEED)\n",
    "val_df, test_df = train_test_split(test_val_df, stratify=test_val_df['Latin name'], test_size=0.5, random_state = SEED)\n",
    "\n",
    "train_ds = Recordings30(train_df, recording_dir=RECORDINGS_DIR, noises_dir=NOISES_DIR, sample_rate=SAMPLE_RATE, device = DEVICE)\n",
    "val_ds = Recordings30(val_df, recording_dir=RECORDINGS_DIR, noises_dir=NOISES_DIR, sample_rate = 32000, device = DEVICE)\n",
    "test_ds = Recordings30(test_df, recording_dir=RECORDINGS_DIR, noises_dir=NOISES_DIR,sample_rate = 32000,device = DEVICE)\n",
    "\n",
    "train_dl  = DataLoader(train_ds, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "val_dl  = DataLoader(val_ds, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "test_dl  = DataLoader(test_ds, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0.51893968,  1.27070614,  1.94016008,  1.08587615,  1.45975912,\n        0.66487577, 10.02652068,  6.30107034,  0.66167309,  1.13336084,\n        1.94290429,  0.70732921,  2.63653231,  0.55975278,  0.73065603,\n        1.44440939,  0.82500501,  1.4706995 ,  0.55188161,  6.54111111,\n        2.13961578,  1.02971014,  1.20494152,  1.33752029,  3.8585206 ,\n        0.8065962 ,  9.15755556,  0.20450102,  1.63722686,  1.14756335])"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                                  classes = np.sort(df['Latin name'].unique()),\n",
    "                                                  y = df.loc[:, 'Latin name']\n",
    "                                                 )\n",
    "class_weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T19:07:26.389904619Z",
     "start_time": "2023-11-28T19:07:26.374266016Z"
    }
   },
   "id": "eb02132a70eef36d"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "{0: 'Alauda arvensis',\n 1: 'Anas platyrhynchos',\n 2: 'Apus apus',\n 3: 'Asio otus',\n 4: 'Buteo buteo',\n 5: 'Carduelis carduelis',\n 6: 'Ciconia ciconia',\n 7: 'Columba livia',\n 8: 'Corvus corax',\n 9: 'Corvus cornix',\n 10: 'Corvus frugilegus',\n 11: 'Cuculus canorus',\n 12: 'Cygnus olor',\n 13: 'Dendrocopos major',\n 14: 'Garrulus glandarius',\n 15: 'Grus grus',\n 16: 'Hirundo rustica',\n 17: 'Lophophanes cristatus',\n 18: 'Passer domesticus',\n 19: 'Phalacrocorax carbo',\n 20: 'Phasianus colchicus',\n 21: 'Phoenicurus ochruros',\n 22: 'Pica pica',\n 23: 'Picus viridis',\n 24: 'Sternula albifrons',\n 25: 'Sturnus vulgaris',\n 26: 'Tetrao urogallus',\n 27: 'Turdus merula',\n 28: 'Turdus torquatus',\n 29: 'Turdus viscivorus'}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.get_mapping()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T14:41:39.232749754Z",
     "start_time": "2023-11-28T14:41:39.219681980Z"
    }
   },
   "id": "a53679ae9de68ac6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c612cd209e56d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T00:14:21.742990903Z",
     "start_time": "2023-11-21T00:12:32.622505320Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_ds.visualize_dataset(3207,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc7af23f048046c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Prepare a model, loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce99d90c296dcb74",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T00:14:21.656201808Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnn = CNNNetwork().to(DEVICE)\n",
    "summary(cnn, (1, 64, 251)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51da132857d56e87",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-21T19:10:07.895087253Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0c61402a5f18de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T00:14:22.175624750Z",
     "start_time": "2023-11-21T00:14:21.700289440Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(),\n",
    "                             lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2380e0608b51937c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d4d6b60baba8699",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-28T19:02:46.981086271Z",
     "start_time": "2023-11-28T19:02:42.461447342Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 20:02:44.270796: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-28 20:02:44.414751: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-28 20:02:44.816148: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-28 20:02:45.910458: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 18\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEPOCH \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(epoch_number \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# Make sure gradient tracking is on, and do a pass over the data\u001B[39;00m\n\u001B[0;32m---> 18\u001B[0m \u001B[43mcnn\u001B[49m\u001B[38;5;241m.\u001B[39mtrain(\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     19\u001B[0m avg_loss \u001B[38;5;241m=\u001B[39m train_one_epoch(epoch_number, writer, train_dl, optimizer, loss_fn, cnn, DEVICE)\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Set the model to evaluation mode, disabling dropout and using population \u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# statistics for batch normalization.\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'cnn' is not defined"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import sys\n",
    "from training.training_utils import train_one_epoch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from training.validation_metrics import calculate_metric\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter(f'logs/fashion_trainer_{timestamp}')\n",
    "epoch_number = 0\n",
    "\n",
    "best_vloss = sys.float_info.max\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "    \n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    cnn.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer, train_dl, optimizer, loss_fn, cnn, DEVICE)\n",
    "    \n",
    "    # Set the model to evaluation mode, disabling dropout and using population \n",
    "    # statistics for batch normalization.\n",
    "    cnn.eval()\n",
    "    running_vloss = 0.0\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(val_dl):\n",
    "            vinputs, vlabels = vdata\n",
    "            vinputs = torch.unsqueeze(vinputs, dim=1)\n",
    "            voutputs = cnn(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "    \n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print(\"#############################################################\")\n",
    "    print(\"Epoch results:\")\n",
    "    print(f'Loss train {avg_loss} valid loss: {avg_vloss}')\n",
    "    validation_f1_score = calculate_metric(cnn, val_dl, metric=f1_score)\n",
    "    train_f1_score = None\n",
    "    print(f'F1 score train {train_f1_score} valid f1 score {validation_f1_score}')\n",
    "    print(\"#############################################################\\n\\n\")\n",
    "    \n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    \n",
    "    \n",
    "    writer.add_scalars('Macro_averaged_f1_score',\n",
    "                    { 'Validation' : validation_f1_score},\n",
    "                    epoch_number + 1)\n",
    "    \n",
    "    writer.flush()\n",
    "    \n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = f'model_{timestamp}_{epoch_number}'\n",
    "        torch.save(cnn.state_dict(), model_path)\n",
    "    \n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06f71feecd3bda2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48662bbc67b9c3ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-21T18:10:25.959808049Z",
     "start_time": "2023-11-21T18:10:25.914461016Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.save(cnn.state_dict(),\"saved_models/cnn_1.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
