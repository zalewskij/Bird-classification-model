{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68726db873b8dce7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Classes and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e1e43838f725aab",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T19:06:24.355228800Z",
     "start_time": "2023-11-29T19:06:20.567415800Z"
    }
   },
   "outputs": [],
   "source": [
    "from birdclassification.preprocessing.filtering import filter_recordings_30\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from training.dataset import Recordings30\n",
    "from birdclassification.visualization.plots import plot_torch_spectrogram\n",
    "from training.cnn_training_torch.CNN_model import CNNNetwork\n",
    "from torchsummary import summary\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "816e75a17dc17a2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T19:06:24.371228600Z",
     "start_time": "2023-11-29T19:06:24.355228800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacek\\PycharmProjects\\Bird-classification-model\\venv\\lib\\site-packages\\torch\\cuda\\__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11070). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ..\\c10\\cuda\\CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "SEED = 123\n",
    "RECORDINGS_DIR = Path(\"D:\\\\JAcek\\\\recordings_30\")\n",
    "NOISES_DIR = Path('D:\\\\JAcek\\\\noises_dir')\n",
    "WRITER_DIR = Path(\"D:\\\\JAcek\\\\logs\\\\\", f\"cnn_{TIMESTAMP}\")\n",
    "\n",
    "SAMPLE_RATE = 32000\n",
    "NUM_SAMPLES = SAMPLE_RATE * 1\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 8\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2500b5a9a57f175",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Prepare dataset and dataloaders, visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63a6e7eb0ea22a95",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T19:06:28.175449500Z",
     "start_time": "2023-11-29T19:06:24.367228700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacek\\PycharmProjects\\Bird-classification-model\\birdclassification\\preprocessing\\filtering.py:72: DtypeWarning: Columns (10,39,43,44,45,46,47,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  recordings = pd.read_csv(filepath_recordings)\n"
     ]
    }
   ],
   "source": [
    "df = filter_recordings_30(\"../../data/xeno_canto_recordings.csv\", \"../../data/bird-list-extended.csv\", )\n",
    "\n",
    "#subset for test purpose\n",
    "# df = df.sample(frac = 0.1, random_state=SEED)\n",
    "\n",
    "train_df, test_val_df = train_test_split(df, stratify=df['Latin name'], test_size=0.2, random_state = SEED)\n",
    "val_df, test_df = train_test_split(test_val_df, stratify=test_val_df['Latin name'], test_size=0.5, random_state = SEED)\n",
    "\n",
    "train_ds = Recordings30(train_df, recording_dir=RECORDINGS_DIR, noises_dir=NOISES_DIR, sample_rate=SAMPLE_RATE, device = DEVICE)\n",
    "val_ds = Recordings30(val_df, recording_dir=RECORDINGS_DIR, noises_dir=NOISES_DIR, sample_rate = 32000, device = DEVICE)\n",
    "test_ds = Recordings30(test_df, recording_dir=RECORDINGS_DIR, noises_dir=NOISES_DIR,sample_rate = 32000,device = DEVICE)\n",
    "\n",
    "train_dl  = DataLoader(train_ds, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "val_dl  = DataLoader(val_ds, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "test_dl  = DataLoader(test_ds, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0.51893968,  1.27070614,  1.94016008,  1.08587615,  1.45975912,\n        0.66487577, 10.02652068,  6.30107034,  0.66167309,  1.13336084,\n        1.94290429,  0.70732921,  2.63653231,  0.55975278,  0.73065603,\n        1.44440939,  0.82500501,  1.4706995 ,  0.55188161,  6.54111111,\n        2.13961578,  1.02971014,  1.20494152,  1.33752029,  3.8585206 ,\n        0.8065962 ,  9.15755556,  0.20450102,  1.63722686,  1.14756335])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
    "                                                  classes = np.sort(df['Latin name'].unique()),\n",
    "                                                  y = df.loc[:, 'Latin name']\n",
    "                                                 )\n",
    "class_weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T19:06:28.195617300Z",
     "start_time": "2023-11-29T19:06:28.177722400Z"
    }
   },
   "id": "eb02132a70eef36d"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "{0: 'Alauda arvensis',\n 1: 'Anas platyrhynchos',\n 2: 'Apus apus',\n 3: 'Asio otus',\n 4: 'Buteo buteo',\n 5: 'Carduelis carduelis',\n 6: 'Ciconia ciconia',\n 7: 'Columba livia',\n 8: 'Corvus corax',\n 9: 'Corvus cornix',\n 10: 'Corvus frugilegus',\n 11: 'Cuculus canorus',\n 12: 'Cygnus olor',\n 13: 'Dendrocopos major',\n 14: 'Garrulus glandarius',\n 15: 'Grus grus',\n 16: 'Hirundo rustica',\n 17: 'Lophophanes cristatus',\n 18: 'Passer domesticus',\n 19: 'Phalacrocorax carbo',\n 20: 'Phasianus colchicus',\n 21: 'Phoenicurus ochruros',\n 22: 'Pica pica',\n 23: 'Picus viridis',\n 24: 'Sternula albifrons',\n 25: 'Sturnus vulgaris',\n 26: 'Tetrao urogallus',\n 27: 'Turdus merula',\n 28: 'Turdus torquatus',\n 29: 'Turdus viscivorus'}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.get_mapping()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T19:06:28.214611600Z",
     "start_time": "2023-11-29T19:06:28.191617Z"
    }
   },
   "id": "a53679ae9de68ac6"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c61c612cd209e56d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T19:06:28.226611400Z",
     "start_time": "2023-11-29T19:06:28.207616900Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_ds.visualize_dataset(3207,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc7af23f048046c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Prepare a model, loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce99d90c296dcb74",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T19:06:28.238610300Z",
     "start_time": "2023-11-29T19:06:28.222610700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 16, 33, 126]         --\n",
      "|    └─Conv2d: 2-1                       [-1, 16, 66, 253]         160\n",
      "|    └─ReLU: 2-2                         [-1, 16, 66, 253]         --\n",
      "|    └─MaxPool2d: 2-3                    [-1, 16, 33, 126]         --\n",
      "├─Sequential: 1-2                        [-1, 32, 17, 64]          --\n",
      "|    └─Conv2d: 2-4                       [-1, 32, 35, 128]         4,640\n",
      "|    └─ReLU: 2-5                         [-1, 32, 35, 128]         --\n",
      "|    └─MaxPool2d: 2-6                    [-1, 32, 17, 64]          --\n",
      "├─Sequential: 1-3                        [-1, 64, 9, 33]           --\n",
      "|    └─Conv2d: 2-7                       [-1, 64, 19, 66]          18,496\n",
      "|    └─ReLU: 2-8                         [-1, 64, 19, 66]          --\n",
      "|    └─MaxPool2d: 2-9                    [-1, 64, 9, 33]           --\n",
      "├─Sequential: 1-4                        [-1, 128, 5, 17]          --\n",
      "|    └─Conv2d: 2-10                      [-1, 128, 11, 35]         73,856\n",
      "|    └─ReLU: 2-11                        [-1, 128, 11, 35]         --\n",
      "|    └─MaxPool2d: 2-12                   [-1, 128, 5, 17]          --\n",
      "├─Flatten: 1-5                           [-1, 10880]               --\n",
      "├─Linear: 1-6                            [-1, 30]                  326,430\n",
      "==========================================================================================\n",
      "Total params: 423,582\n",
      "Trainable params: 423,582\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 74.97\n",
      "==========================================================================================\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 4.12\n",
      "Params size (MB): 1.62\n",
      "Estimated Total Size (MB): 5.80\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\n├─Sequential: 1-1                        [-1, 16, 33, 126]         --\n|    └─Conv2d: 2-1                       [-1, 16, 66, 253]         160\n|    └─ReLU: 2-2                         [-1, 16, 66, 253]         --\n|    └─MaxPool2d: 2-3                    [-1, 16, 33, 126]         --\n├─Sequential: 1-2                        [-1, 32, 17, 64]          --\n|    └─Conv2d: 2-4                       [-1, 32, 35, 128]         4,640\n|    └─ReLU: 2-5                         [-1, 32, 35, 128]         --\n|    └─MaxPool2d: 2-6                    [-1, 32, 17, 64]          --\n├─Sequential: 1-3                        [-1, 64, 9, 33]           --\n|    └─Conv2d: 2-7                       [-1, 64, 19, 66]          18,496\n|    └─ReLU: 2-8                         [-1, 64, 19, 66]          --\n|    └─MaxPool2d: 2-9                    [-1, 64, 9, 33]           --\n├─Sequential: 1-4                        [-1, 128, 5, 17]          --\n|    └─Conv2d: 2-10                      [-1, 128, 11, 35]         73,856\n|    └─ReLU: 2-11                        [-1, 128, 11, 35]         --\n|    └─MaxPool2d: 2-12                   [-1, 128, 5, 17]          --\n├─Flatten: 1-5                           [-1, 10880]               --\n├─Linear: 1-6                            [-1, 30]                  326,430\n==========================================================================================\nTotal params: 423,582\nTrainable params: 423,582\nNon-trainable params: 0\nTotal mult-adds (M): 74.97\n==========================================================================================\nInput size (MB): 0.06\nForward/backward pass size (MB): 4.12\nParams size (MB): 1.62\nEstimated Total Size (MB): 5.80\n=========================================================================================="
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = CNNNetwork().to(DEVICE)\n",
    "summary(cnn, (1, 64, 251)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51da132857d56e87",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T19:06:28.250609100Z",
     "start_time": "2023-11-29T19:06:28.238610300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "CNNNetwork(\n  (conv1): Sequential(\n    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (conv2): Sequential(\n    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (conv3): Sequential(\n    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (conv4): Sequential(\n    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (flatten): Flatten(start_dim=1, end_dim=-1)\n  (linear): Linear(in_features=10880, out_features=30, bias=True)\n)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc0c61402a5f18de",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T19:06:28.608220400Z",
     "start_time": "2023-11-29T19:06:28.250609100Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(),\n",
    "                             lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2380e0608b51937c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d4d6b60baba8699",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-29T19:09:05.287132900Z",
     "start_time": "2023-11-29T19:06:28.608220400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "Loss after batch 10: 3.716287684440613\n",
      "Loss after batch 20: 3.279300594329834\n",
      "Loss after batch 30: 3.126720690727234\n",
      "Loss after batch 40: 3.166953706741333\n",
      "Loss after batch 50: 3.1313658475875856\n",
      "Loss after batch 60: 3.045567202568054\n",
      "Loss after batch 70: 3.07205753326416\n",
      "Loss after batch 80: 3.0313016414642333\n",
      "Loss after batch 90: 2.9936838865280153\n",
      "Loss after batch 100: 2.9438982009887695\n",
      "Loss after batch 110: 3.0177878379821776\n",
      "Loss after batch 120: 2.969415283203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x000002BEDE3B3880>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jacek\\PycharmProjects\\Bird-classification-model\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"C:\\Users\\Jacek\\PycharmProjects\\Bird-classification-model\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1442, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"C:\\Program Files\\Python310\\lib\\multiprocessing\\process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"C:\\Program Files\\Python310\\lib\\multiprocessing\\popen_spawn_win32.py\", line 108, in wait\n",
      "    res = _winapi.WaitForSingleObject(int(self._handle), msecs)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 17\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# Make sure gradient tracking is on, and do a pass over the data\u001B[39;00m\n\u001B[0;32m     16\u001B[0m cnn\u001B[38;5;241m.\u001B[39mtrain(\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m---> 17\u001B[0m avg_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_one_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch_number\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwriter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcnn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mDEVICE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# Set the model to evaluation mode, disabling dropout and using population \u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;66;03m# statistics for batch normalization.\u001B[39;00m\n\u001B[0;32m     21\u001B[0m cnn\u001B[38;5;241m.\u001B[39meval()\n",
      "File \u001B[1;32m~\\PycharmProjects\\Bird-classification-model\\training\\training_utils.py:36\u001B[0m, in \u001B[0;36mtrain_one_epoch\u001B[1;34m(epoch_index, tb_writer, training_loader, optimizer, loss_fn, model, device)\u001B[0m\n\u001B[0;32m     33\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     35\u001B[0m \u001B[38;5;66;03m# Make predictions for this batch\u001B[39;00m\n\u001B[1;32m---> 36\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# Compute the loss and its gradients\u001B[39;00m\n\u001B[0;32m     39\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss_fn(outputs\u001B[38;5;241m.\u001B[39mto(device), labels\u001B[38;5;241m.\u001B[39mlong()\u001B[38;5;241m.\u001B[39mto(device))\n",
      "File \u001B[1;32m~\\PycharmProjects\\Bird-classification-model\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\Bird-classification-model\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Bird-classification-model\\training\\cnn_training_torch\\CNN_model.py:60\u001B[0m, in \u001B[0;36mCNNNetwork.forward\u001B[1;34m(self, input_data)\u001B[0m\n\u001B[0;32m     58\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv1(input_data)\n\u001B[0;32m     59\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv2(x)\n\u001B[1;32m---> 60\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv3\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv4(x)\n\u001B[0;32m     62\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mflatten(x)\n",
      "File \u001B[1;32m~\\PycharmProjects\\Bird-classification-model\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\Bird-classification-model\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Bird-classification-model\\venv\\lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    213\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    214\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 215\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Bird-classification-model\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\Bird-classification-model\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Bird-classification-model\\venv\\lib\\site-packages\\torch\\nn\\modules\\activation.py:101\u001B[0m, in \u001B[0;36mReLU.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    100\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrelu\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\Bird-classification-model\\venv\\lib\\site-packages\\torch\\nn\\functional.py:1471\u001B[0m, in \u001B[0;36mrelu\u001B[1;34m(input, inplace)\u001B[0m\n\u001B[0;32m   1469\u001B[0m     result \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrelu_(\u001B[38;5;28minput\u001B[39m)\n\u001B[0;32m   1470\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1471\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrelu\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1472\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from training.training_utils import train_one_epoch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from training.validation_metrics import calculate_metric\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "writer = SummaryWriter(WRITER_DIR)\n",
    "epoch_number = 0\n",
    "\n",
    "best_vloss = sys.float_info.max\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "    \n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    cnn.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer, train_dl, optimizer, loss_fn, cnn, DEVICE)\n",
    "    \n",
    "    # Set the model to evaluation mode, disabling dropout and using population \n",
    "    # statistics for batch normalization.\n",
    "    cnn.eval()\n",
    "    running_vloss = 0.0\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(val_dl):\n",
    "            vinputs, vlabels = vdata\n",
    "            vinputs = torch.unsqueeze(vinputs, dim=1)\n",
    "            voutputs = cnn(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "    \n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print(\"#############################################################\")\n",
    "    print(\"Epoch results:\")\n",
    "    print(f'Loss train {avg_loss} valid loss: {avg_vloss}')\n",
    "    validation_f1_score = calculate_metric(cnn, val_dl, metric=f1_score)\n",
    "    train_f1_score = None\n",
    "    print(f'F1 score train {train_f1_score} valid f1 score {validation_f1_score}')\n",
    "    print(\"#############################################################\\n\\n\")\n",
    "    \n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    \n",
    "    \n",
    "    writer.add_scalars('Macro_averaged_f1_score',\n",
    "                    { 'Validation' : validation_f1_score},\n",
    "                    epoch_number + 1)\n",
    "    \n",
    "    writer.flush()\n",
    "    \n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = f'model_{TIMESTAMP}_{epoch_number}'\n",
    "        torch.save(cnn.state_dict(), model_path)\n",
    "    \n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06f71feecd3bda2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48662bbc67b9c3ba",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-29T19:09:05.278288900Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(cnn.state_dict(),\"saved_models/cnn_1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-29T19:09:05.282289400Z"
    }
   },
   "id": "68075c8247be056a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-29T19:09:05.282289400Z"
    }
   },
   "id": "b59112619ae6f3b8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
