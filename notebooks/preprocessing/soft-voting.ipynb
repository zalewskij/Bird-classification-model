{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "import math\n",
    "from birdclassification.preprocessing.filtering import filter_recordings_30\n",
    "from birdclassification.preprocessing.utils import mix_down, right_pad\n",
    "from birdclassification.training.cnn_training_torch.CNN_model import CNNNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SEED = 123\n",
    "RECORDINGS_DIR = '/mnt/d/recordings_30/'\n",
    "SAMPLE_RATE = 32000\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBinaryNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 4 conv blocks / flatten / liniear / softmax\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=16,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=64,\n",
    "                out_channels=128,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=2\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.linear1 = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                10880, 2\n",
    "            )\n",
    "        )\n",
    "        # self.linear2 = nn.Linear(\n",
    "        #     1024, 1\n",
    "        # )\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        x = self.conv1(input_data)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear1(x)\n",
    "        #logits = self.linear2(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../../birdclassification/training/saved_models/cnn_1.pt'\n",
    "cnn = CNNNetwork()\n",
    "cnn.load_state_dict(torch.load(PATH))\n",
    "cnn.eval()\n",
    "cnn.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_BINARY = '../../birdclassification/training/saved_models/binary_classifier.pt'\n",
    "binary = CNNBinaryNetwork()\n",
    "binary.load_state_dict(torch.load(PATH_BINARY))\n",
    "binary.eval()\n",
    "binary.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullRecordings(Dataset):\n",
    "    def __init__(self, df, recording_dir):\n",
    "        df['filepath'] = df.apply(lambda x: Path(recording_dir, x['Latin name'], f\"{str(x['id'])}.mp3\"), axis=1)\n",
    "        le = LabelEncoder()\n",
    "        df['label'] = le.fit_transform(df['Latin name'])\n",
    "\n",
    "        self.filepath = df['filepath'].to_numpy()\n",
    "        self.label = df['label'].to_numpy()\n",
    "        self.recording_dir = recording_dir\n",
    "        self.le_name_mapping = dict(zip(le.transform(le.classes_), le.classes_))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.filepath.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio, sr = torchaudio.load(self.filepath[idx])\n",
    "        if sr != SAMPLE_RATE:\n",
    "            print(\"SR !!!!!\")\n",
    "        audio = mix_down(audio)\n",
    "        audio = right_pad(audio, minimal_length=3*SAMPLE_RATE)\n",
    "        label = self.label[idx]\n",
    "        return audio, label\n",
    "\n",
    "    def get_mapping(self):\n",
    "        return self.le_name_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_collate(batch):\n",
    "    data = [item[0] for item in batch]\n",
    "    target = [item[1] for item in batch]\n",
    "    target = torch.LongTensor(target)\n",
    "    return [data, target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filter_recordings_30(\"../../data/xeno_canto_recordings.csv\", \"../../data/bird-list-extended.csv\", )\n",
    "\n",
    "train_df, test_val_df = train_test_split(df, stratify=df['Latin name'], test_size=0.1, random_state = SEED)\n",
    "val_df, test_df = train_test_split(test_val_df, stratify=test_val_df['Latin name'], test_size=0.5, random_state = SEED)\n",
    "\n",
    "train_ds = FullRecordings(train_df, recording_dir=RECORDINGS_DIR)\n",
    "val_ds = FullRecordings(val_df, recording_dir=RECORDINGS_DIR)\n",
    "test_ds = FullRecordings(test_df, recording_dir=RECORDINGS_DIR)\n",
    "\n",
    "train_dl  = DataLoader(train_ds, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, collate_fn=my_collate)\n",
    "val_dl  = DataLoader(val_ds, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, collate_fn=my_collate)\n",
    "test_dl  = DataLoader(test_ds, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, collate_fn=my_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mel_spectrogram(y, sr, n_fft, hop_length, number_of_bands = 64, fmin = 150, fmax = 15000):\n",
    "    M = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=number_of_bands, fmin=fmin, fmax=fmax)\n",
    "    M_db = librosa.power_to_db(M, ref=np.max)\n",
    "    return torch.from_numpy(M_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(waveform, start_time, end_time, sr, n_fft, hop_length, length_in_seconds):\n",
    "    length = length_in_seconds * sr\n",
    "\n",
    "    spectrograms = list(map(\n",
    "        lambda start: generate_mel_spectrogram(waveform[start:start+length], sr, n_fft, hop_length),\n",
    "        [s * sr for s in range(start_time, end_time + 1 - length_in_seconds, length_in_seconds - 1)]\n",
    "    ))\n",
    "\n",
    "    return list(map(lambda spectrogram: torch.unsqueeze(spectrogram, dim=0), spectrograms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_audio(input_tensors, model, binary_classifier, device):\n",
    "    softmax = torch.nn.Softmax(dim=1)\n",
    "    cumulative_output = torch.zeros(30).to(device)\n",
    "    not_recognised = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_tensor in input_tensors:\n",
    "            input = torch.unsqueeze(input_tensor, dim=0).to(device)\n",
    "            is_bird = binary_classifier(input)\n",
    "            is_bird = softmax(is_bird)[0, 1]\n",
    "\n",
    "            if is_bird > 0.9:\n",
    "                output = model(input)\n",
    "                output = softmax(output).squeeze()\n",
    "                cumulative_output = torch.maximum(output, cumulative_output)\n",
    "            else:\n",
    "                not_recognised += 1\n",
    "\n",
    "    if cumulative_output.sum() > 0:\n",
    "        cumulative_output.divide_(cumulative_output.sum())\n",
    "\n",
    "    return cumulative_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_fragments(input):\n",
    "    input = input.squeeze(0)\n",
    "    length = math.floor(input.shape[0] / SAMPLE_RATE)\n",
    "    return preprocess_audio(input, 0, length, sr=SAMPLE_RATE, n_fft=512, hop_length=384, length_in_seconds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input):\n",
    "    outputs = prepare_fragments(input)\n",
    "    results = classify_audio(outputs, cnn, binary, DEVICE)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_result(result):\n",
    "  return 30 if torch.all(result < 0.01) else torch.argmax(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models_outputs(input):\n",
    "    input_tensors = prepare_fragments(input)\n",
    "    softmax = torch.nn.Softmax(dim=1)\n",
    "    outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_tensor in input_tensors:\n",
    "            input = torch.unsqueeze(input_tensor, dim=0).to(DEVICE)\n",
    "            is_bird = binary(input)\n",
    "            is_bird = softmax(is_bird)[0, 1]\n",
    "\n",
    "            output = cnn(input)\n",
    "            output = softmax(output).squeeze()\n",
    "\n",
    "            outputs.append((output, is_bird))\n",
    "\n",
    "    # here\n",
    "    results = [result[0] * 5 * (result[1] - 0.8) for result in outputs if result[1] >= 0.8]\n",
    "\n",
    "    if len(results) == 0:\n",
    "        results = [result[0] * 2 * (result[1] - 0.5) for result in outputs if result[1] >= 0.5]\n",
    "\n",
    "    results = torch.stack(results).sum(dim=0).div(len(results)) if len(results) > 0 else torch.zeros(30)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack([torch.tensor([1, 2, 0, 0.6]), torch.tensor([0.1, 1.9, 0.01, 0.4]), torch.tensor([1.1, 1.8, 0, 0.5])]).max(dim=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_models_outputs(test_ds[18][0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(test_ds[18][0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = torch.Tensor()\n",
    "predicted_labels = torch.Tensor()\n",
    "start_time = time()\n",
    "loader_size = len(test_dl.dataset)\n",
    "samples = 0\n",
    "\n",
    "for i, data in enumerate(test_dl):\n",
    "    inputs, labels = data\n",
    "    samples += len(inputs)\n",
    "    predictions = torch.tensor([interpret_result(get_models_outputs(input.numpy())) for input in inputs])\n",
    "    predicted_labels = torch.cat((predicted_labels, predictions))\n",
    "    true_labels = torch.cat((true_labels, labels))\n",
    "    print(f'After batch {i + 1}: {samples / loader_size:.4f}; time elapsed: {time() - start_time:.2f}')\n",
    "\n",
    "true_labels = true_labels.cpu()\n",
    "predicted_labels = predicted_labels.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list(train_ds.get_mapping().values())\n",
    "names.append('No bird')\n",
    "classification = classification_report(true_labels, predicted_labels, target_names=names, labels=list(range(31)))\n",
    "cm = confusion_matrix(true_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(0, classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "df_cm = pd.DataFrame(cm)\n",
    "df_cm.columns = names\n",
    "df_cm.index = names\n",
    "plt.figure(figsize = (40,40))\n",
    "s = sns.heatmap(df_cm, annot=True, cmap = 'binary', fmt='.2f')\n",
    "s.set_xlabel('Prediction', fontsize=24, labelpad=70)\n",
    "s.set_ylabel('True label', fontsize=24, labelpad=70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
